{"cells":[{"cell_type":"markdown","source":["d-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cd4ba887-53b4-4515-a35c-67d417432a4c"}}},{"cell_type":"markdown","source":["-sandbox\n## Optimizing Delta\n\nIn this notebook, you'll see some examples of how you can optimize your queries using Delta Engine, which is built-in to the Databricks Runtime 7.0. It is also part of open source [Delta Lake](https://delta.io/).\n\nThe data contains information about US-based flight schedules from 2008. It is made available to us via [Databricks Datasets](https://docs.databricks.com/data/databricks-datasets.html). \n\nFirst, we will create a standard table using Parquet format and then we'll run a query to observe the timing. \n\nThen, we'll run the same query on a Delta table using Delta Engine optimizations and compare the two. \n\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> Databricks includes a variety of datasets that you can use to continue learning, or just for practice! Check out the docs for copyable Python code that you can use to see what sets are available. \n\nRun the cell below to set up your classroom environment."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ad3e3d5d-76a2-463c-a366-74e2e9f75e29"}}},{"cell_type":"code","source":["%run ../Includes/Classroom-Setup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"62c1302d-a054-433f-9f42-c1f196e382ad"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Mounting course-specific datasets to <b>/mnt/training</b>...</br>Datasets are already mounted to <b>/mnt/training</b> from <b>s3a://databricks-corp-training/common</b>","textData":null,"removedWidgets":[],"addedWidgets":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["Mounting course-specific datasets to <b>/mnt/training</b>...</br>Datasets are already mounted to <b>/mnt/training</b> from <b>s3a://databricks-corp-training/common</b>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">res1: Boolean = true\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">res1: Boolean = true\n</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">res2: Boolean = true\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">res2: Boolean = true\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Create a Parquet table\nRun the command below to create a Parquet table. \n\nCommand took 6.77 minutes"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"faf1169e-2c68-4b89-ab40-f92cf2a300e5"}}},{"cell_type":"code","source":["%sql\nDROP TABLE IF EXISTS flights;\n-- Create a standard table and import US based flights for year 2008\n-- USING Clause: Specify parquet format for a standard table\n-- PARTITIONED BY clause: Orginize data based on \"Origin\" column (Originating Airport code).\n-- FROM Clause: Import data from a csv file. \nCREATE TABLE flights\nUSING\n  parquet\nPARTITIONED BY\n  (Origin)\nSELECT\n  _c0 AS Year,\n  _c1 AS MONTH,\n  _c2 AS DayofMonth,\n  _c3 AS DayOfWeek,\n  _c4 AS DepartureTime,\n  _c5 AS CRSDepartureTime,\n  _c6 AS ArrivalTime,\n  _c7 AS CRSArrivalTime,\n  _c8 AS UniqueCarrier,\n  _c9 AS FlightNumber,\n  _c10 AS TailNumber,\n  _c11 AS ActualElapsedTime,\n  _c12 AS CRSElapsedTime,\n  _c13 AS AirTime,\n  _c14 AS ArrivalDelay,\n  _c15 AS DepartureDelay,\n  _c16 AS Origin,\n  _c17 AS Destination,\n  _c18 AS Distance,\n  _c19 AS TaxiIn,\n  _c20 AS TaxiOut,\n  _c21 AS Cancelled,\n  _c22 AS CancellationCode,\n  _c23 AS Diverted,\n  _c24 AS CarrierDelay,\n  _c25 AS WeatherDelay,\n  _c26 AS NASDelay,\n  _c27 AS SecurityDelay,\n  _c28 AS LateAircraftDelay\nFROM                              -- This table is being read in directly from a csv file. \n  csv.`dbfs:/databricks-datasets/asa/airlines/2008.csv` "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7ae721a2-27d0-4df1-a0d3-47b50716ba8c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[],"aggError":"","aggData":[],"addedWidgets":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Highest monthly total (Parquet)\n\nRun the query to get the top 20 cities with the highest monthly total flights on the first day of the week.\n\nBe sure to note the time when the query finishes. \n\nCommand took 3.42 minutes"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6aa3f9e5-d008-4bd3-acf3-09ec73cc4466"}}},{"cell_type":"code","source":["%sql\nSELECT Month, Origin, count(*) as TotalFlights \nFROM flights\nWHERE DayOfWeek = 1 \nGROUP BY Month, Origin \nORDER BY TotalFlights DESC\nLIMIT 20;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"484f63f9-232d-45b6-a8bd-110a359bad93"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["6","ATL",6046],["3","ATL",6019],["12","ATL",5800],["9","ATL",5722],["6","ORD",5241],["3","ORD",5072],["9","ORD",4931],["7","ATL",4894],["8","ATL",4821],["4","ATL",4798],["11","ATL",4776],["10","ATL",4684],["5","ATL",4656],["2","ATL",4601],["1","ATL",4540],["12","ORD",4473],["7","ORD",4249],["8","ORD",4171],["4","ORD",4140],["5","ORD",4134]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"Month","type":"\"string\"","metadata":"{}"},{"name":"Origin","type":"\"string\"","metadata":"{}"},{"name":"TotalFlights","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Month</th><th>Origin</th><th>TotalFlights</th></tr></thead><tbody><tr><td>6</td><td>ATL</td><td>6046</td></tr><tr><td>3</td><td>ATL</td><td>6019</td></tr><tr><td>12</td><td>ATL</td><td>5800</td></tr><tr><td>9</td><td>ATL</td><td>5722</td></tr><tr><td>6</td><td>ORD</td><td>5241</td></tr><tr><td>3</td><td>ORD</td><td>5072</td></tr><tr><td>9</td><td>ORD</td><td>4931</td></tr><tr><td>7</td><td>ATL</td><td>4894</td></tr><tr><td>8</td><td>ATL</td><td>4821</td></tr><tr><td>4</td><td>ATL</td><td>4798</td></tr><tr><td>11</td><td>ATL</td><td>4776</td></tr><tr><td>10</td><td>ATL</td><td>4684</td></tr><tr><td>5</td><td>ATL</td><td>4656</td></tr><tr><td>2</td><td>ATL</td><td>4601</td></tr><tr><td>1</td><td>ATL</td><td>4540</td></tr><tr><td>12</td><td>ORD</td><td>4473</td></tr><tr><td>7</td><td>ORD</td><td>4249</td></tr><tr><td>8</td><td>ORD</td><td>4171</td></tr><tr><td>4</td><td>ORD</td><td>4140</td></tr><tr><td>5</td><td>ORD</td><td>4134</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Create a Delta Table\nRun the query below to compare Delta to Parquet. Note, this is the exact same command running on the exact same cluster configuration. Recall that the two operations take roughly the same amount of \"work\" from Spark. We have to read in a huge csv file, partition it by origin, and store it in a new, columnar format. Plus, Delta is creating a transaction log and tagging the files with important and useful metadata! \n\nCommand took 6.37 minutes"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"15e77c91-a43b-4469-99a1-52bb6c3a5334"}}},{"cell_type":"code","source":["%sql\nDROP TABLE IF EXISTS flights;\n-- Create a standard table and import US based flights for year 2008\n-- USING Clause: Specify \"delta\" format instead of the standard parquet format\n-- PARTITIONED BY clause: Orginize data based on \"Origin\" column (Originating Airport code).\n-- FROM Clause: Import data from a csv file.\nCREATE TABLE flights\nUSING\n  delta\nPARTITIONED BY\n  (Origin)\nSELECT\n  _c0 AS Year,\n  _c1 AS MONTH,\n  _c2 AS DayofMonth,\n  _c3 AS DayOfWeek,\n  _c4 AS DepartureTime,\n  _c5 AS CRSDepartureTime,\n  _c6 AS ArrivalTime,\n  _c7 AS CRSArrivalTime,\n  _c8 AS UniqueCarrier,\n  _c9 AS FlightNumber,\n  _c10 AS TailNumber,\n  _c11 AS ActualElapsedTime,\n  _c12 AS CRSElapsedTime,\n  _c13 AS AirTime,\n  _c14 AS ArrivalDelay,\n  _c15 AS DepartureDelay,\n  _c16 AS Origin,\n  _c17 AS Destination,\n  _c18 AS Distance,\n  _c19 AS TaxiIn,\n  _c20 AS TaxiOut,\n  _c21 AS Cancelled,\n  _c22 AS CancellationCode,\n  _c23 AS Diverted,\n  _c24 AS CarrierDelay,\n  _c25 AS WeatherDelay,\n  _c26 AS NASDelay,\n  _c27 AS SecurityDelay,\n  _c28 AS LateAircraftDelay\nFROM\n  csv.`dbfs:/databricks-datasets/asa/airlines/2008.csv`;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d7380d39-5dcb-4244-8f16-87dde32151bc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[],"aggError":"","aggData":[],"addedWidgets":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Optimize your table\n\nIf your organization continuously writes data to a Delta table, it will over time accumulate a large number of files, especially if you add data in small batches. For analysts, a common complaint in querying data lakes is read efficiency; and having a large collection of small files to sift through everytime data is queried can create performance problems. Ideally, a large number of small files should be rewritten into a smaller number of larger files on a regular basis, which will improve the speed of read queries from a table. This is known as compaction. You can compact a table using the `OPTIMIZE` command shown below. \n\nZ-ordering co-locates column information (recall that Delta is columnar storage). Co-locality is used by Delta Lake data-skipping algorithms to dramatically reduce the amount of data that needs to be read. You can specify multiple columns for ZORDER BY as a comma-separated list. However, the effectiveness of the locality drops with each additional column. Read more about optimizing Delta tables [here](https://docs.databricks.com/spark/latest/spark-sql/language-manual/delta-optimize.html).\n\nCommand took 14.52 minutes"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a8cb5b9d-20aa-464a-9e4b-fa38dab30aa2"}}},{"cell_type":"code","source":["%sql\nOPTIMIZE flights ZORDER BY (DayofWeek);"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6d001426-b2a3-4f28-a4d4-65ad39916216"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[null,[300,2308,[8663,7000927,384088.0,300,115226524],[6343,1141358,62759.0,2308,144849962],304,["minCubeSize(107374182400)",[0,0],[2312,144878958],0,[2308,144849962],300,null],1]]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"path","type":"\"string\"","metadata":"{}"},{"name":"metrics","type":"{\"type\":\"struct\",\"fields\":[{\"name\":\"numFilesAdded\",\"type\":\"long\",\"nullable\":false,\"metadata\":{}},{\"name\":\"numFilesRemoved\",\"type\":\"long\",\"nullable\":false,\"metadata\":{}},{\"name\":\"filesAdded\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"min\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"max\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"avg\",\"type\":\"double\",\"nullable\":false,\"metadata\":{}},{\"name\":\"totalFiles\",\"type\":\"long\",\"nullable\":false,\"metadata\":{}},{\"name\":\"totalSize\",\"type\":\"long\",\"nullable\":false,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"filesRemoved\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"min\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"max\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"avg\",\"type\":\"double\",\"nullable\":false,\"metadata\":{}},{\"name\":\"totalFiles\",\"type\":\"long\",\"nullable\":false,\"metadata\":{}},{\"name\":\"totalSize\",\"type\":\"long\",\"nullable\":false,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"partitionsOptimized\",\"type\":\"long\",\"nullable\":false,\"metadata\":{}},{\"name\":\"zOrderStats\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"strategyName\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"inputCubeFiles\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"num\",\"type\":\"long\",\"nullable\":false,\"metadata\":{}},{\"name\":\"size\",\"type\":\"long\",\"nullable\":false,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"inputOtherFiles\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"num\",\"type\":\"long\",\"nullable\":false,\"metadata\":{}},{\"name\":\"size\",\"type\":\"long\",\"nullable\":false,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"inputNumCubes\",\"type\":\"long\",\"nullable\":false,\"metadata\":{}},{\"name\":\"mergedFiles\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"num\",\"type\":\"long\",\"nullable\":false,\"metadata\":{}},{\"name\":\"size\",\"type\":\"long\",\"nullable\":false,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"numOutputCubes\",\"type\":\"long\",\"nullable\":false,\"metadata\":{}},{\"name\":\"mergedNumCubes\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"numBatches\",\"type\":\"long\",\"nullable\":false,\"metadata\":{}}]}","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>metrics</th></tr></thead><tbody><tr><td>null</td><td>List(300, 2308, List(8663, 7000927, 384088.0, 300, 115226524), List(6343, 1141358, 62759.0, 2308, 144849962), 304, List(minCubeSize(107374182400), List(0, 0), List(2312, 144878958), 0, List(2308, 144849962), 300, null), 1)</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Rerun the query\nRun the query below to compare performance for a standard Parquet table with an optimized Delta table. \n\nCommand took 32.42 seconds"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"39ed9715-e450-4367-976f-65dd1619f5cd"}}},{"cell_type":"code","source":["%sql\nSELECT Month, Origin, count(*) as TotalFlights \nFROM flights\nWHERE DayOfWeek = 1 \nGROUP BY Month, Origin \nORDER BY TotalFlights DESC\nLIMIT 20;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"738678d4-3dd5-4f8b-82c9-de84512ad0f5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["6","ATL",6046],["3","ATL",6019],["12","ATL",5800],["9","ATL",5722],["6","ORD",5241],["3","ORD",5072],["9","ORD",4931],["7","ATL",4894],["8","ATL",4821],["4","ATL",4798],["11","ATL",4776],["10","ATL",4684],["5","ATL",4656],["2","ATL",4601],["1","ATL",4540],["12","ORD",4473],["7","ORD",4249],["8","ORD",4171],["4","ORD",4140],["5","ORD",4134]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"Month","type":"\"string\"","metadata":"{}"},{"name":"Origin","type":"\"string\"","metadata":"{}"},{"name":"TotalFlights","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Month</th><th>Origin</th><th>TotalFlights</th></tr></thead><tbody><tr><td>6</td><td>ATL</td><td>6046</td></tr><tr><td>3</td><td>ATL</td><td>6019</td></tr><tr><td>12</td><td>ATL</td><td>5800</td></tr><tr><td>9</td><td>ATL</td><td>5722</td></tr><tr><td>6</td><td>ORD</td><td>5241</td></tr><tr><td>3</td><td>ORD</td><td>5072</td></tr><tr><td>9</td><td>ORD</td><td>4931</td></tr><tr><td>7</td><td>ATL</td><td>4894</td></tr><tr><td>8</td><td>ATL</td><td>4821</td></tr><tr><td>4</td><td>ATL</td><td>4798</td></tr><tr><td>11</td><td>ATL</td><td>4776</td></tr><tr><td>10</td><td>ATL</td><td>4684</td></tr><tr><td>5</td><td>ATL</td><td>4656</td></tr><tr><td>2</td><td>ATL</td><td>4601</td></tr><tr><td>1</td><td>ATL</td><td>4540</td></tr><tr><td>12</td><td>ORD</td><td>4473</td></tr><tr><td>7</td><td>ORD</td><td>4249</td></tr><tr><td>8</td><td>ORD</td><td>4171</td></tr><tr><td>4</td><td>ORD</td><td>4140</td></tr><tr><td>5</td><td>ORD</td><td>4134</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Delta Cache \n\nUsing the Delta cache is an excellent way to optimize performance. Note: The Delta cache is *not* the same as caching in Apache Spark, which we talked about in Module 4. One notable difference is that the Delta cache is stored entirely on the local disk, so that memory is not taken away from other operations within Spark. When enabled, the Delta cache automatically creates a copy of a remote file in local storage so that successive reads are significantly sped up. Unfortunately, to enable it, you must choose a cluster type that is not available in Databricks Community Edition. \n\nTo better understand the differences between Delta caching and Apache Spark caching, please read, [\"Delta and Apache Spark caching.\"](https://docs.databricks.com/delta/optimizations/delta-cache.html#delta-and-apache-spark-caching)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"42867291-da34-45f7-abdb-ec93b9f98b76"}}},{"cell_type":"code","source":["%run ../Includes/Classroom-Cleanup\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b1fae91d-7148-47f2-98d9-f5fa0cb3649d"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"41674e1f-ab68-4c5c-97c8-9403a9da001c"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"8.3 Optimizing Delta","dashboards":[],"language":"python","widgets":{},"notebookOrigID":3431324887126259}},"nbformat":4,"nbformat_minor":0}
